{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tf_agents.networks.q_network import QNetwork\n",
    "import tf_agents.networks.network as network\n",
    "from tf_agents.specs import tensor_spec\n",
    "from snake_game import SnakeGame\n",
    "from scene import Scene\n",
    "from scene_longer_snake import SceneLongerSnake\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input\n",
    "\n",
    "scene = SceneLongerSnake(init_randomly=True, snake_longer_prob=0.95, length_mean=10, length_std=2)\n",
    "episodes_count = 50000\n",
    "random_episodes = 20000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments.tf_py_environment import TFPyEnvironment\n",
    "\n",
    "env = SnakeGame(scene)\n",
    "env = TFPyEnvironment(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 5, 5, 4)]            0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 4, 4, 32)             544       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 512)                  0         ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 128)                  65664     ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 32)                   4128      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 40)                   0         ['dense_1[0][0]',             \n",
      "                                                                     'input_2[0][0]',             \n",
      "                                                                     'input_3[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 4)                    164       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70500 (275.39 KB)\n",
      "Trainable params: 70500 (275.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MyQNetwork(network.Network):\n",
    "    def __init__(self,\n",
    "                 input_tensor_spec,\n",
    "                 action_spec,\n",
    "                 name='MyQNetwork'):\n",
    "        super(MyQNetwork, self).__init__(\n",
    "            input_tensor_spec=input_tensor_spec,\n",
    "            state_spec=(),\n",
    "            name=name)\n",
    "        \n",
    "        self._action_spec = action_spec\n",
    "        matrix_shape = input_tensor_spec[0].shape\n",
    "        obstacles_shape = input_tensor_spec[1].shape\n",
    "        food_direction_shape = input_tensor_spec[2].shape\n",
    "        \n",
    "        input1 = Input(shape=matrix_shape)\n",
    "        input2 = Input(shape=obstacles_shape) # Each value represents if there is a wall or the snake body in the direction, 0 - no wall, 1 - wall\n",
    "        input3 = Input(shape=food_direction_shape) # Each value represents if the food is in the direction, 0 - no food, 1 - food\n",
    "        \n",
    "        conv = Conv2D(32, (2, 2), 1, activation='relu', kernel_initializer='he_normal')(input1)\n",
    "        flat = Flatten()(conv)\n",
    "        dense1 = Dense(128, activation='relu', kernel_initializer='he_normal')(flat)\n",
    "        dense2 = Dense(32, activation='relu', kernel_initializer='he_normal')(dense1)\n",
    "        \n",
    "        concat = tf.keras.layers.concatenate([dense2, input2, input3])\n",
    "        output = Dense(4, activation='linear')(concat)\n",
    "        \n",
    "        self._model = tf.keras.Model(inputs=[input1, input2, input3], outputs=output)\n",
    "        \n",
    "        self._model.summary()\n",
    "\n",
    "    def call(self, observations, step_type=None, network_state=(), training=False):\n",
    "        output = self._model([observations[0], observations[1], observations[2]])\n",
    "        return output, network_state\n",
    "\n",
    "q_net = MyQNetwork(\n",
    "    env.observation_spec(),\n",
    "    env.action_spec())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 5, 5, 4)]            0         []                            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 4, 4, 32)             544       ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 512)                  0         ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 128)                  65664     ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 32)                   4128      ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)        [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 40)                   0         ['dense_4[0][0]',             \n",
      " )                                                                   'input_5[0][0]',             \n",
      "                                                                     'input_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 4)                    164       ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 70500 (275.39 KB)\n",
      "Trainable params: 70500 (275.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the agent\n",
    "from tf_agents.agents.dqn.dqn_agent import DdqnAgent\n",
    "from tensorflow import keras\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.losses import Huber\n",
    "from tf_agents.trajectories import TimeStep\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "optimizer = Adam(learning_rate=0.003)\n",
    "\n",
    "epsilon = keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=episodes_count,\n",
    "    end_learning_rate=0.01\n",
    ")\n",
    "\n",
    "agent = DdqnAgent(\n",
    "    time_step_spec=env.time_step_spec(),\n",
    "    action_spec=env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=Huber(reduction=\"none\"),\n",
    "    gamma=tf.constant(0.95, dtype=tf.float32),\n",
    "    train_step_counter=train_step_counter,\n",
    "    epsilon_greedy=lambda: epsilon(train_step_counter)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the replay buffer\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=env.batch_size,\n",
    "    max_length=100000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training metrics\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "train_metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.EnvironmentSteps(),\n",
    "    tf_metrics.AverageReturnMetric(),\n",
    "    tf_metrics.AverageEpisodeLengthMetric()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the driver\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "\n",
    "collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env,\n",
    "    policy=agent.collect_policy,\n",
    "    observers=[replay_buffer.add_batch] + train_metrics,\n",
    "    num_steps=2\n",
    ")\n",
    "\n",
    "# Run a random policy to fill the replay buffer\n",
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy\n",
    "\n",
    "initial_collect_policy = RandomTFPolicy(env.time_step_spec(), env.action_spec())\n",
    "init_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env,\n",
    "    policy=initial_collect_policy,\n",
    "    observers=[replay_buffer.add_batch],\n",
    "    num_steps=random_episodes\n",
    ")\n",
    "\n",
    "final_time_step, final_policy_state = init_driver.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/juanpablo/miniconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=64,\n",
    "    num_steps=2, # Capaz cambiar esto\n",
    "    num_parallel_calls=5\n",
    ").prefetch(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the training loop\n",
    "\n",
    "from tf_agents.utils.common import function\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.eval.metric_utils import log_metrics\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "collect_driver.run = function(collect_driver.run)\n",
    "agent.train = function(agent.train)\n",
    "\n",
    "def train_agent(n_iterations):\n",
    "    time_step = None\n",
    "    policy_state = agent.collect_policy.get_initial_state(env.batch_size)\n",
    "    iterator = iter(dataset)\n",
    "    for iteration in range(n_iterations):\n",
    "        time_step, policy_state = collect_driver.run(time_step, policy_state)\n",
    "        trajectories, buffer_info = next(iterator)\n",
    "        train_loss = agent.train(trajectories)\n",
    "        if iteration % 1000 == 0:\n",
    "            print(\"Iteration: \", iteration)\n",
    "            print(\"Replay buffer len: \" + str(replay_buffer.num_frames().numpy()))\n",
    "            log_metrics(train_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/juanpablo/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 0\n",
      "\t\t EnvironmentSteps = 2\n",
      "\t\t AverageReturn = 0.0\n",
      "\t\t AverageEpisodeLength = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Replay buffer len: 43514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 335\n",
      "\t\t EnvironmentSteps = 2002\n",
      "\t\t AverageReturn = -12638.5\n",
      "\t\t AverageEpisodeLength = 7.900000095367432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1000\n",
      "Replay buffer len: 45849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 471\n",
      "\t\t EnvironmentSteps = 4002\n",
      "\t\t AverageReturn = -17297.0\n",
      "\t\t AverageEpisodeLength = 26.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2000\n",
      "Replay buffer len: 47985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 647\n",
      "\t\t EnvironmentSteps = 6002\n",
      "\t\t AverageReturn = -23053.0\n",
      "\t\t AverageEpisodeLength = 7.699999809265137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3000\n",
      "Replay buffer len: 50161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 781\n",
      "\t\t EnvironmentSteps = 8002\n",
      "\t\t AverageReturn = -27078.0\n",
      "\t\t AverageEpisodeLength = 14.800000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4000\n",
      "Replay buffer len: 52295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 927\n",
      "\t\t EnvironmentSteps = 10002\n",
      "\t\t AverageReturn = -31263.0\n",
      "\t\t AverageEpisodeLength = 16.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  5000\n",
      "Replay buffer len: 54441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1070\n",
      "\t\t EnvironmentSteps = 12002\n",
      "\t\t AverageReturn = -35153.0\n",
      "\t\t AverageEpisodeLength = 16.600000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  6000\n",
      "Replay buffer len: 56584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1207\n",
      "\t\t EnvironmentSteps = 14002\n",
      "\t\t AverageReturn = -38786.5\n",
      "\t\t AverageEpisodeLength = 11.800000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  7000\n",
      "Replay buffer len: 58721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1350\n",
      "\t\t EnvironmentSteps = 16002\n",
      "\t\t AverageReturn = -42694.0\n",
      "\t\t AverageEpisodeLength = 19.399999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  8000\n",
      "Replay buffer len: 60864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1478\n",
      "\t\t EnvironmentSteps = 18002\n",
      "\t\t AverageReturn = -45881.5\n",
      "\t\t AverageEpisodeLength = 7.599999904632568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  9000\n",
      "Replay buffer len: 62992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1592\n",
      "\t\t EnvironmentSteps = 20002\n",
      "\t\t AverageReturn = -48505.0\n",
      "\t\t AverageEpisodeLength = 17.200000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  10000\n",
      "Replay buffer len: 65106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1740\n",
      "\t\t EnvironmentSteps = 22002\n",
      "\t\t AverageReturn = -52607.5\n",
      "\t\t AverageEpisodeLength = 9.800000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  11000\n",
      "Replay buffer len: 67254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1868\n",
      "\t\t EnvironmentSteps = 24002\n",
      "\t\t AverageReturn = -55740.5\n",
      "\t\t AverageEpisodeLength = 15.600000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  12000\n",
      "Replay buffer len: 69382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1975\n",
      "\t\t EnvironmentSteps = 26002\n",
      "\t\t AverageReturn = -58134.0\n",
      "\t\t AverageEpisodeLength = 13.399999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  13000\n",
      "Replay buffer len: 71489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2096\n",
      "\t\t EnvironmentSteps = 28002\n",
      "\t\t AverageReturn = -61244.5\n",
      "\t\t AverageEpisodeLength = 13.300000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  14000\n",
      "Replay buffer len: 73609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2218\n",
      "\t\t EnvironmentSteps = 30002\n",
      "\t\t AverageReturn = -64353.5\n",
      "\t\t AverageEpisodeLength = 20.200000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  15000\n",
      "Replay buffer len: 75732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2347\n",
      "\t\t EnvironmentSteps = 32002\n",
      "\t\t AverageReturn = -67592.0\n",
      "\t\t AverageEpisodeLength = 14.199999809265137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  16000\n",
      "Replay buffer len: 77861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2466\n",
      "\t\t EnvironmentSteps = 34002\n",
      "\t\t AverageReturn = -70383.0\n",
      "\t\t AverageEpisodeLength = 12.899999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  17000\n",
      "Replay buffer len: 79980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2565\n",
      "\t\t EnvironmentSteps = 36002\n",
      "\t\t AverageReturn = -72515.0\n",
      "\t\t AverageEpisodeLength = 23.700000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  18000\n",
      "Replay buffer len: 82079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2665\n",
      "\t\t EnvironmentSteps = 38002\n",
      "\t\t AverageReturn = -74664.0\n",
      "\t\t AverageEpisodeLength = 16.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  19000\n",
      "Replay buffer len: 84179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2773\n",
      "\t\t EnvironmentSteps = 40002\n",
      "\t\t AverageReturn = -77067.0\n",
      "\t\t AverageEpisodeLength = 18.799999237060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  20000\n",
      "Replay buffer len: 86287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2880\n",
      "\t\t EnvironmentSteps = 42002\n",
      "\t\t AverageReturn = -79382.5\n",
      "\t\t AverageEpisodeLength = 14.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  21000\n",
      "Replay buffer len: 88394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2957\n",
      "\t\t EnvironmentSteps = 44002\n",
      "\t\t AverageReturn = -80675.0\n",
      "\t\t AverageEpisodeLength = 22.399999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  22000\n",
      "Replay buffer len: 90471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3069\n",
      "\t\t EnvironmentSteps = 46002\n",
      "\t\t AverageReturn = -83135.5\n",
      "\t\t AverageEpisodeLength = 9.199999809265137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  23000\n",
      "Replay buffer len: 92583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3166\n",
      "\t\t EnvironmentSteps = 48002\n",
      "\t\t AverageReturn = -85080.5\n",
      "\t\t AverageEpisodeLength = 9.699999809265137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  24000\n",
      "Replay buffer len: 94680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3255\n",
      "\t\t EnvironmentSteps = 50002\n",
      "\t\t AverageReturn = -86831.5\n",
      "\t\t AverageEpisodeLength = 23.299999237060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  25000\n",
      "Replay buffer len: 96769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3340\n",
      "\t\t EnvironmentSteps = 52002\n",
      "\t\t AverageReturn = -88534.5\n",
      "\t\t AverageEpisodeLength = 27.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  26000\n",
      "Replay buffer len: 98854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3423\n",
      "\t\t EnvironmentSteps = 54002\n",
      "\t\t AverageReturn = -90009.0\n",
      "\t\t AverageEpisodeLength = 23.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  27000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3511\n",
      "\t\t EnvironmentSteps = 56002\n",
      "\t\t AverageReturn = -91528.0\n",
      "\t\t AverageEpisodeLength = 17.799999237060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  28000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3602\n",
      "\t\t EnvironmentSteps = 58002\n",
      "\t\t AverageReturn = -93164.0\n",
      "\t\t AverageEpisodeLength = 21.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  29000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3677\n",
      "\t\t EnvironmentSteps = 60002\n",
      "\t\t AverageReturn = -94169.0\n",
      "\t\t AverageEpisodeLength = 21.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  30000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3765\n",
      "\t\t EnvironmentSteps = 62002\n",
      "\t\t AverageReturn = -95876.5\n",
      "\t\t AverageEpisodeLength = 22.200000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  31000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3861\n",
      "\t\t EnvironmentSteps = 64002\n",
      "\t\t AverageReturn = -97628.5\n",
      "\t\t AverageEpisodeLength = 7.800000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  32000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3949\n",
      "\t\t EnvironmentSteps = 66002\n",
      "\t\t AverageReturn = -99124.0\n",
      "\t\t AverageEpisodeLength = 15.800000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  33000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4027\n",
      "\t\t EnvironmentSteps = 68002\n",
      "\t\t AverageReturn = -100384.5\n",
      "\t\t AverageEpisodeLength = 24.600000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  34000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4121\n",
      "\t\t EnvironmentSteps = 70002\n",
      "\t\t AverageReturn = -102109.5\n",
      "\t\t AverageEpisodeLength = 18.899999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  35000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4191\n",
      "\t\t EnvironmentSteps = 72002\n",
      "\t\t AverageReturn = -103093.0\n",
      "\t\t AverageEpisodeLength = 25.899999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  36000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4269\n",
      "\t\t EnvironmentSteps = 74002\n",
      "\t\t AverageReturn = -104247.0\n",
      "\t\t AverageEpisodeLength = 41.599998474121094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  37000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4344\n",
      "\t\t EnvironmentSteps = 76002\n",
      "\t\t AverageReturn = -105282.5\n",
      "\t\t AverageEpisodeLength = 44.70000076293945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  38000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4415\n",
      "\t\t EnvironmentSteps = 78002\n",
      "\t\t AverageReturn = -106104.5\n",
      "\t\t AverageEpisodeLength = 27.600000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  39000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4486\n",
      "\t\t EnvironmentSteps = 80002\n",
      "\t\t AverageReturn = -106968.5\n",
      "\t\t AverageEpisodeLength = 22.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  40000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4547\n",
      "\t\t EnvironmentSteps = 82002\n",
      "\t\t AverageReturn = -107626.5\n",
      "\t\t AverageEpisodeLength = 31.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  41000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4615\n",
      "\t\t EnvironmentSteps = 84002\n",
      "\t\t AverageReturn = -108393.0\n",
      "\t\t AverageEpisodeLength = 33.400001525878906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  42000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4691\n",
      "\t\t EnvironmentSteps = 86002\n",
      "\t\t AverageReturn = -109485.0\n",
      "\t\t AverageEpisodeLength = 23.899999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  43000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4752\n",
      "\t\t EnvironmentSteps = 88002\n",
      "\t\t AverageReturn = -109826.5\n",
      "\t\t AverageEpisodeLength = 24.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  44000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4814\n",
      "\t\t EnvironmentSteps = 90002\n",
      "\t\t AverageReturn = -110333.0\n",
      "\t\t AverageEpisodeLength = 29.899999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  45000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4872\n",
      "\t\t EnvironmentSteps = 92002\n",
      "\t\t AverageReturn = -110607.0\n",
      "\t\t AverageEpisodeLength = 34.599998474121094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  46000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4931\n",
      "\t\t EnvironmentSteps = 94002\n",
      "\t\t AverageReturn = -110920.5\n",
      "\t\t AverageEpisodeLength = 38.20000076293945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  47000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4992\n",
      "\t\t EnvironmentSteps = 96002\n",
      "\t\t AverageReturn = -111426.5\n",
      "\t\t AverageEpisodeLength = 38.70000076293945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  48000\n",
      "Replay buffer len: 100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 5049\n",
      "\t\t EnvironmentSteps = 98002\n",
      "\t\t AverageReturn = -111918.5\n",
      "\t\t AverageEpisodeLength = 38.79999923706055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  49000\n",
      "Replay buffer len: 100000\n"
     ]
    }
   ],
   "source": [
    "train_agent(episodes_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 3 0 0]\n",
      "  [0 1 0 0 0]\n",
      "  [0 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 3 0 0]\n",
      "  [0 2 1 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 3 0 0 0]\n",
      "  [0 0 1 0 0]\n",
      "  [0 2 2 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 3 0 0 0]\n",
      "  [0 1 2 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 1 0 0 0]\n",
      "  [0 2 2 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [0 0 0 3 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 2 1 0 0]\n",
      "  [0 2 2 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 3 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 2 2 1 0]\n",
      "  [0 2 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 3 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 0 0 1 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 3 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 2 2 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 0 0 1 0]\n",
      "  [0 0 0 3 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [3 0 2 2 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 0 0 1 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [3 0 0 2 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 0 1 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [3 0 0 0 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 1 2 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [3 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 2 0]\n",
      "  [1 2 2 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [3 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [1 0 0 0 0]\n",
      "  [2 2 2 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [3 0 0 0 0]\n",
      "  [1 0 0 0 0]\n",
      "  [2 0 0 0 0]\n",
      "  [2 2 2 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [1 0 0 0 0]\n",
      "  [2 0 0 0 0]\n",
      "  [2 0 0 3 0]\n",
      "  [2 2 2 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 1 0 0 0]\n",
      "  [2 0 0 0 0]\n",
      "  [2 0 0 3 0]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 0 0 0]\n",
      "  [2 1 0 0 0]\n",
      "  [2 0 0 3 0]\n",
      "  [2 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True  True False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 0 0 0]\n",
      "  [2 2 0 0 0]\n",
      "  [2 1 0 3 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 0 0 0]\n",
      "  [2 2 0 0 0]\n",
      "  [0 2 1 3 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 0 0 0]\n",
      "  [0 2 0 0 0]\n",
      "  [0 2 2 3 0]\n",
      "  [0 0 1 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 2 0 0 0]\n",
      "  [0 2 0 0 0]\n",
      "  [0 2 2 3 0]\n",
      "  [0 0 2 1 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 2 0 0 0]\n",
      "  [0 2 0 0 0]\n",
      "  [0 2 2 1 0]\n",
      "  [0 3 2 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 2 0 0 0]\n",
      "  [0 2 2 2 1]\n",
      "  [0 3 2 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 1]\n",
      "  [0 2 2 2 2]\n",
      "  [0 3 2 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 1 2]\n",
      "  [0 0 2 2 2]\n",
      "  [0 3 2 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 1 2 2]\n",
      "  [0 0 0 2 2]\n",
      "  [0 3 2 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 1 2 2 2]\n",
      "  [0 0 0 2 2]\n",
      "  [0 3 0 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 2 2 2 2]\n",
      "  [0 1 0 2 2]\n",
      "  [0 3 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 3]\n",
      "  [0 2 2 2 2]\n",
      "  [0 2 0 2 2]\n",
      "  [0 1 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 3]\n",
      "  [0 2 2 2 2]\n",
      "  [0 2 0 0 2]\n",
      "  [1 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 3]\n",
      "  [0 2 2 2 2]\n",
      "  [1 2 0 0 0]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 3]\n",
      "  [1 2 2 2 0]\n",
      "  [2 2 0 0 0]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [1 0 0 0 3]\n",
      "  [2 2 2 0 0]\n",
      "  [2 2 0 0 0]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 1 0 0 3]\n",
      "  [2 2 0 0 0]\n",
      "  [2 2 0 0 0]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 1 0 3]\n",
      "  [2 0 0 0 0]\n",
      "  [2 2 0 0 0]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 2 1 3]\n",
      "  [2 0 0 0 0]\n",
      "  [2 0 0 0 0]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 2 2 1]\n",
      "  [2 0 0 0 3]\n",
      "  [2 0 0 0 0]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 2 2 2]\n",
      "  [2 0 0 0 1]\n",
      "  [2 0 0 0 3]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True  True False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 3 0 0]\n",
      "  [2 2 2 2 2]\n",
      "  [2 0 0 0 2]\n",
      "  [2 0 0 0 1]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True  True False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 3 0 0]\n",
      "  [2 2 2 2 2]\n",
      "  [2 0 0 0 2]\n",
      "  [2 0 0 0 2]\n",
      "  [2 0 0 0 1]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 3 0 0]\n",
      "  [2 2 2 2 2]\n",
      "  [2 0 0 0 2]\n",
      "  [2 0 0 0 2]\n",
      "  [0 0 0 1 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 3 0 0]\n",
      "  [2 2 2 2 2]\n",
      "  [2 0 0 0 2]\n",
      "  [0 0 0 0 2]\n",
      "  [0 0 1 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 3 0 0]\n",
      "  [2 2 2 2 2]\n",
      "  [0 0 0 0 2]\n",
      "  [0 0 1 0 2]\n",
      "  [0 0 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 3 0 0]\n",
      "  [0 2 2 2 2]\n",
      "  [0 0 1 0 2]\n",
      "  [0 0 2 0 2]\n",
      "  [0 0 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 3 0 0]\n",
      "  [0 0 2 2 2]\n",
      "  [0 1 2 0 2]\n",
      "  [0 0 2 0 2]\n",
      "  [0 0 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 3 0 0]\n",
      "  [0 1 0 2 2]\n",
      "  [0 2 2 0 2]\n",
      "  [0 0 2 0 2]\n",
      "  [0 0 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 1 3 0 0]\n",
      "  [0 2 0 0 2]\n",
      "  [0 2 2 0 2]\n",
      "  [0 0 2 0 2]\n",
      "  [0 0 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 2 1 0 0]\n",
      "  [0 2 0 0 2]\n",
      "  [0 2 2 0 2]\n",
      "  [0 0 2 0 2]\n",
      "  [3 0 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True  True False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 1 0 0]\n",
      "  [0 2 2 0 2]\n",
      "  [0 0 2 0 2]\n",
      "  [3 0 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True  True False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 2 1 0]\n",
      "  [0 2 2 0 0]\n",
      "  [0 0 2 0 2]\n",
      "  [3 0 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 2 2 1 0]\n",
      "  [0 0 2 0 0]\n",
      "  [3 0 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True  True False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 0 2 1 0]\n",
      "  [3 0 2 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True  True False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 0 2 2 1]\n",
      "  [3 0 2 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 0 2 2 2]\n",
      "  [3 0 0 0 1]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 0 0 2 2]\n",
      "  [3 0 0 1 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 2 0 2 0]\n",
      "  [0 0 0 2 2]\n",
      "  [3 0 1 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 0 0 2 2]\n",
      "  [3 1 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 0 0 2 0]\n",
      "  [3 0 0 2 2]\n",
      "  [1 2 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 2 2 2 0]\n",
      "  [0 0 0 2 3]\n",
      "  [1 0 0 2 2]\n",
      "  [2 2 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 2 2 0 0]\n",
      "  [0 0 2 2 0]\n",
      "  [0 0 0 2 3]\n",
      "  [2 1 0 2 2]\n",
      "  [2 2 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 2 0 0]\n",
      "  [0 0 2 2 0]\n",
      "  [0 0 0 2 3]\n",
      "  [2 2 1 2 2]\n",
      "  [2 2 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 2 2 0]\n",
      "  [0 0 1 2 3]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 1 2 2 3]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[False False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [1 2 2 2 3]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [1 0 0 0 0]\n",
      "  [2 2 2 0 3]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 1 0 0 0]\n",
      "  [2 2 2 0 3]\n",
      "  [2 2 2 0 2]\n",
      "  [2 2 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 1 0 0]\n",
      "  [2 2 2 0 3]\n",
      "  [2 2 2 0 0]\n",
      "  [2 2 2 2 2]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 2 1 0]\n",
      "  [2 2 2 0 3]\n",
      "  [2 2 2 0 0]\n",
      "  [2 2 2 2 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [2 2 2 2 0]\n",
      "  [2 2 2 1 3]\n",
      "  [2 2 2 0 0]\n",
      "  [2 2 2 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True  True False False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[3 0 0 0 0]\n",
      "  [2 2 2 2 0]\n",
      "  [2 2 2 2 1]\n",
      "  [2 2 2 0 0]\n",
      "  [2 2 2 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True False]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[3 0 0 0 0]\n",
      "  [2 2 2 2 1]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 0 0]\n",
      "  [2 2 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True False  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[3 0 0 0 1]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 0 0]\n",
      "  [2 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[3 0 0 1 2]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[3 0 1 2 2]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 2 2]\n",
      "  [0 2 2 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[3 1 2 2 2]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 2 2]\n",
      "  [0 0 2 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[False  True  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[1 2 2 2 2]\n",
      "  [2 2 2 2 2]\n",
      "  [2 2 2 2 2]\n",
      "  [0 0 2 3 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Direction:\n",
      " tf.Tensor([[ True  True  True  True]], shape=(1, 4), dtype=bool)\n",
      "Action:  [3]\n",
      "Total reward:  30.0\n",
      "Total steps:  77\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the agent\n",
    "\n",
    "test_scene = Scene(init_randomly=True)\n",
    "test_env = SnakeGame(test_scene)\n",
    "test_env = TFPyEnvironment(test_env)\n",
    "\n",
    "time_step = test_env.reset()\n",
    "rewards = []\n",
    "steps = 0\n",
    "\n",
    "while not time_step.is_last() and steps < 200:\n",
    "    steps += 1\n",
    "    print(\"Map:\\n\", np.argmax(time_step.observation[0], axis=3))\n",
    "    print(\"Direction:\\n\", time_step.observation[1])\n",
    "    action_step = agent.policy.action(time_step)\n",
    "    print(\"Action: \", action_step.action.numpy())\n",
    "    time_step = test_env.step(action_step.action)\n",
    "    rewards.append(time_step.reward.numpy()[0])\n",
    "    \n",
    "print(\"Total reward: \", sum(rewards))\n",
    "print(\"Total steps: \", steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  10\n",
      "Avg reward:  40.0\n",
      "Episode:  20\n",
      "Avg reward:  38.57142857142857\n",
      "Episode:  30\n",
      "Avg reward:  39.516129032258064\n",
      "Episode:  40\n",
      "Avg reward:  38.53658536585366\n",
      "Episode:  50\n",
      "Avg reward:  37.64705882352941\n",
      "Episode:  60\n",
      "Avg reward:  37.78688524590164\n",
      "Episode:  70\n",
      "Avg reward:  36.76056338028169\n",
      "Episode:  80\n",
      "Avg reward:  38.20987654320987\n",
      "Episode:  90\n",
      "Avg reward:  37.582417582417584\n",
      "Episode:  100\n",
      "Avg reward:  36.633663366336634\n",
      "Episode:  110\n",
      "Avg reward:  37.027027027027025\n",
      "Episode:  120\n",
      "Avg reward:  36.611570247933884\n",
      "Episode:  130\n",
      "Avg reward:  37.51908396946565\n",
      "Episode:  140\n",
      "Avg reward:  37.4468085106383\n",
      "Episode:  150\n",
      "Avg reward:  38.50993377483444\n",
      "Episode:  160\n",
      "Avg reward:  38.1055900621118\n",
      "Episode:  170\n",
      "Avg reward:  39.21052631578947\n",
      "Episode:  180\n",
      "Avg reward:  39.58563535911602\n",
      "Episode:  190\n",
      "Avg reward:  39.81675392670157\n",
      "Episode:  200\n",
      "Avg reward:  40.0\n",
      "Episode:  210\n",
      "Avg reward:  40.426540284360186\n",
      "Episode:  220\n",
      "Avg reward:  40.36199095022624\n",
      "Episode:  230\n",
      "Avg reward:  41.06060606060606\n",
      "Episode:  240\n",
      "Avg reward:  40.850622406639005\n",
      "Episode:  250\n",
      "Avg reward:  40.43824701195219\n",
      "Episode:  260\n",
      "Avg reward:  40.15325670498084\n",
      "Episode:  270\n",
      "Avg reward:  40.16605166051661\n",
      "Episode:  280\n",
      "Avg reward:  40.05338078291815\n",
      "Episode:  290\n",
      "Avg reward:  39.828178694158076\n",
      "Episode:  300\n",
      "Avg reward:  39.71760797342193\n",
      "Episode:  310\n",
      "Avg reward:  39.72668810289389\n",
      "Episode:  320\n",
      "Avg reward:  39.73520249221184\n",
      "Episode:  330\n",
      "Avg reward:  39.59214501510574\n",
      "Episode:  340\n",
      "Avg reward:  39.3108504398827\n",
      "Episode:  350\n",
      "Avg reward:  38.96011396011396\n",
      "Episode:  360\n",
      "Avg reward:  38.78116343490305\n",
      "Episode:  370\n",
      "Avg reward:  38.58490566037736\n",
      "Episode:  380\n",
      "Avg reward:  38.58267716535433\n",
      "Episode:  390\n",
      "Avg reward:  38.47826086956522\n",
      "Episode:  400\n",
      "Avg reward:  38.790523690773064\n",
      "Episode:  410\n",
      "Avg reward:  38.80778588807786\n",
      "Episode:  420\n",
      "Avg reward:  38.56294536817102\n",
      "Episode:  430\n",
      "Avg reward:  38.74709976798144\n",
      "Episode:  440\n",
      "Avg reward:  39.0249433106576\n",
      "Episode:  450\n",
      "Avg reward:  39.01330376940133\n",
      "Episode:  460\n",
      "Avg reward:  38.82863340563991\n",
      "Episode:  470\n",
      "Avg reward:  38.57749469214438\n",
      "Episode:  480\n",
      "Avg reward:  38.43035343035343\n",
      "Episode:  490\n",
      "Avg reward:  38.4826883910387\n",
      "Average steps per episode:  70.96572580645162\n",
      "Average reward per episode:  38.57\n",
      "Total 500 episodes:  4\n",
      "Wins:  26\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count the average steps per episode\n",
    "\n",
    "n = 500\n",
    "total_steps = 0\n",
    "total_reward = 0\n",
    "steps = 0\n",
    "total_500 = 0\n",
    "wins = 0\n",
    "\n",
    "for i in range(n):\n",
    "    if i % 10 == 0 and i != 0:\n",
    "        print(\"Episode: \", i)\n",
    "        \n",
    "    time_step = test_env.reset()\n",
    "    steps = 0\n",
    "    episode_reward = 0\n",
    "    while not time_step.is_last() and steps < 500:\n",
    "        steps += 1\n",
    "        action_step = agent.policy.action(time_step)\n",
    "        time_step = test_env.step(action_step.action)\n",
    "        reward = time_step.reward.numpy()[0]\n",
    "        total_reward += reward\n",
    "        episode_reward += reward\n",
    "        \n",
    "    if episode_reward == 115:\n",
    "        wins += 1\n",
    "    \n",
    "    if steps == 500:\n",
    "        total_500 += 1\n",
    "    else:\n",
    "        total_steps += steps\n",
    "        \n",
    "    if i % 10 == 0 and i != 0:\n",
    "        print(\"Avg reward: \", total_reward / (i + 1))\n",
    "        \n",
    "if steps == 500:\n",
    "    print(\"500 episodes reached\")\n",
    "    \n",
    "print(\"Average steps per episode: \", total_steps / (n - total_500))\n",
    "print(\"Average reward per episode: \", total_reward / n)\n",
    "print(\"Total 500 episodes: \", total_500)\n",
    "print(\"Wins: \", wins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "115.0 == 115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/_7s8wxw93cngpt5f7bg5s3hm0000gn/T/ipykernel_21588/1164216016.py:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(q_net._model, \"q_network.h5\")\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save the q network weights\n",
    "tf.keras.models.save_model(q_net._model, \"q_network.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
