{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tf_agents.networks.q_network import QNetwork\n",
    "import tf_agents.networks.network as network\n",
    "from tf_agents.specs import tensor_spec\n",
    "from snake_game import SnakeGame\n",
    "from scene import Scene\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input\n",
    "\n",
    "scene = Scene(init_randomly=True)\n",
    "episodes_count = 50000\n",
    "random_episodes = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments.tf_py_environment import TFPyEnvironment\n",
    "\n",
    "env = SnakeGame(scene)\n",
    "env = TFPyEnvironment(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 5, 5, 4)]            0         []                            \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 16)             272       ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 256)                  0         ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 64)                   16448     ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 16)                   1040      ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, 4)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 20)                   0         ['dense_4[0][0]',             \n",
      " )                                                                   'input_6[0][0]']             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 4)                    84        ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 17844 (69.70 KB)\n",
      "Trainable params: 17844 (69.70 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class MyQNetwork(network.Network):\n",
    "    def __init__(self,\n",
    "                 input_tensor_spec,\n",
    "                 action_spec,\n",
    "                 name='MyQNetwork'):\n",
    "        super(MyQNetwork, self).__init__(\n",
    "            input_tensor_spec=input_tensor_spec,\n",
    "            state_spec=(),\n",
    "            name=name)\n",
    "        \n",
    "        self._action_spec = action_spec\n",
    "        matrix_shape = input_tensor_spec[\"scene\"].shape\n",
    "        \n",
    "        input1 = Input(shape=matrix_shape)\n",
    "        input2 = Input(shape=(4,)) # Each value represents if there is a wall or the snake body in the direction, 0 - no wall, 1 - wall\n",
    "        \n",
    "        conv = Conv2D(16, (2, 2), 1, activation='relu', kernel_initializer='he_normal')(input1)\n",
    "        flat = Flatten()(conv)\n",
    "        dense1 = Dense(64, activation='relu', kernel_initializer='he_normal')(flat)\n",
    "        dense2 = Dense(16, activation='relu', kernel_initializer='he_normal')(dense1)\n",
    "        \n",
    "        concat = tf.keras.layers.concatenate([dense2, input2])\n",
    "        output = Dense(4, activation='linear')(concat)\n",
    "        \n",
    "        self._model = tf.keras.Model(inputs=[input1, input2], outputs=output)\n",
    "        \n",
    "        print(self._model.summary())\n",
    "\n",
    "    def call(self, observations, step_type=None, network_state=(), training=False):\n",
    "        output = self._model(observations)\n",
    "        return output, network_state\n",
    "\n",
    "q_net = MyQNetwork(\n",
    "    env.observation_spec(),\n",
    "    env.action_spec())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'MyQNetwork' (type MyQNetwork).\n\nMissing data for input \"input_5\". You passed a data dictionary with keys ['scene', 'array_1d']. Expected the following keys: ['input_5', 'input_6']\n\nCall arguments received by layer 'MyQNetwork' (type MyQNetwork):\n  • observations={'scene': 'tf.Tensor(shape=(1, 5, 5, 4), dtype=float32)', 'array_1d': 'tf.Tensor(shape=(1, 4), dtype=bool)'}\n  • step_type=tf.Tensor(shape=(1,), dtype=int32)\n  • network_state=()\n  • training=False\n  In call to configurable 'DqnAgent' (<class 'tf_agents.agents.dqn.dqn_agent.DqnAgent'>)\n  In call to configurable 'DdqnAgent' (<class 'tf_agents.agents.dqn.dqn_agent.DdqnAgent'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.003\u001b[39m)\n\u001b[1;32m     11\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mschedules\u001b[38;5;241m.\u001b[39mPolynomialDecay(\n\u001b[1;32m     12\u001b[0m     initial_learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     13\u001b[0m     decay_steps\u001b[38;5;241m=\u001b[39mepisodes_count,\n\u001b[1;32m     14\u001b[0m     end_learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mDdqnAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_step_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_step_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_network\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtd_errors_loss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mHuber\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_counter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_step_counter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon_greedy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_step_counter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gin/config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m scope_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in scope \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scope_str) \u001b[38;5;28;01mif\u001b[39;00m scope_str \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1604\u001b[0m err_str \u001b[38;5;241m=\u001b[39m err_str\u001b[38;5;241m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[0;32m-> 1605\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment_exception_message_and_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gin/utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m proxy \u001b[38;5;241m=\u001b[39m ExceptionProxy()\n\u001b[1;32m     40\u001b[0m ExceptionProxy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(exception)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m proxy\u001b[38;5;241m.\u001b[39mwith_traceback(exception\u001b[38;5;241m.\u001b[39m__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gin/config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m scope_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in scope \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scope_str) \u001b[38;5;28;01mif\u001b[39;00m scope_str \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1604\u001b[0m err_str \u001b[38;5;241m=\u001b[39m err_str\u001b[38;5;241m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[0;32m-> 1605\u001b[0m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment_exception_message_and_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gin/utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m proxy \u001b[38;5;241m=\u001b[39m ExceptionProxy()\n\u001b[1;32m     40\u001b[0m ExceptionProxy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(exception)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m proxy\u001b[38;5;241m.\u001b[39mwith_traceback(exception\u001b[38;5;241m.\u001b[39m__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/agents/dqn/dqn_agent.py:233\u001b[0m, in \u001b[0;36mDqnAgent.__init__\u001b[0;34m(self, time_step_spec, action_spec, q_network, optimizer, observation_and_action_constraint_splitter, epsilon_greedy, n_step_update, boltzmann_temperature, emit_log_probability, target_q_network, target_update_tau, target_update_period, td_errors_loss_fn, gamma, reward_scale_factor, gradient_clipping, debug_summaries, summarize_grads_and_vars, train_step_counter, training_data_spec, name)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_and_action_constraint_splitter:\n\u001b[1;32m    230\u001b[0m   net_observation_spec, _ \u001b[38;5;241m=\u001b[39m observation_and_action_constraint_splitter(\n\u001b[1;32m    231\u001b[0m       net_observation_spec\n\u001b[1;32m    232\u001b[0m   )\n\u001b[0;32m--> 233\u001b[0m \u001b[43mq_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_observation_spec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_q_network:\n\u001b[1;32m    235\u001b[0m   target_q_network\u001b[38;5;241m.\u001b[39mcreate_variables(net_observation_spec)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/networks/network.py:223\u001b[0m, in \u001b[0;36mNetwork.create_variables\u001b[0;34m(self, input_tensor_spec, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m initial_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_initial_state(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    222\u001b[0m step_type \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfill((\u001b[38;5;241m1\u001b[39m,), time_step\u001b[38;5;241m.\u001b[39mStepType\u001b[38;5;241m.\u001b[39mFIRST)\n\u001b[0;32m--> 223\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_calc_unbatched_spec\u001b[39m(x):\n\u001b[1;32m    228\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Build Network output spec by removing previously added batch dimension.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m    Specs without batch dimension representing x.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/networks/network.py:440\u001b[0m, in \u001b[0;36mNetwork.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(network_state)\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m network_state \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, ())\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetwork_state\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m call_argspec\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m call_argspec\u001b[38;5;241m.\u001b[39mkeywords\n\u001b[1;32m    437\u001b[0m ):\n\u001b[1;32m    438\u001b[0m   normalized_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetwork_state\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 440\u001b[0m outputs, new_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnormalized_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pytype: disable=attribute-error  # typed-keras\u001b[39;00m\n\u001b[1;32m    442\u001b[0m nest_utils\u001b[38;5;241m.\u001b[39massert_matching_dtypes_and_inner_shapes(\n\u001b[1;32m    443\u001b[0m     new_state,\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_spec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m     specs_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`state_spec`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, new_state\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m, in \u001b[0;36mMyQNetwork.call\u001b[0;34m(self, observations, step_type, network_state, training)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, observations, step_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, network_state\u001b[38;5;241m=\u001b[39m(), training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 30\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, network_state\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'MyQNetwork' (type MyQNetwork).\n\nMissing data for input \"input_5\". You passed a data dictionary with keys ['scene', 'array_1d']. Expected the following keys: ['input_5', 'input_6']\n\nCall arguments received by layer 'MyQNetwork' (type MyQNetwork):\n  • observations={'scene': 'tf.Tensor(shape=(1, 5, 5, 4), dtype=float32)', 'array_1d': 'tf.Tensor(shape=(1, 4), dtype=bool)'}\n  • step_type=tf.Tensor(shape=(1,), dtype=int32)\n  • network_state=()\n  • training=False\n  In call to configurable 'DqnAgent' (<class 'tf_agents.agents.dqn.dqn_agent.DqnAgent'>)\n  In call to configurable 'DdqnAgent' (<class 'tf_agents.agents.dqn.dqn_agent.DdqnAgent'>)"
     ]
    }
   ],
   "source": [
    "# Create the agent\n",
    "from tf_agents.agents.dqn.dqn_agent import DdqnAgent\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import Huber\n",
    "from tf_agents.trajectories import TimeStep\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "optimizer = Adam(learning_rate=0.003)\n",
    "\n",
    "epsilon = keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=0.1,\n",
    "    decay_steps=episodes_count,\n",
    "    end_learning_rate=0.01\n",
    ")\n",
    "\n",
    "agent = DdqnAgent(\n",
    "    time_step_spec=env.time_step_spec(),\n",
    "    action_spec=env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=Huber(reduction=\"none\"),\n",
    "    gamma=tf.constant(0.95, dtype=tf.float32),\n",
    "    train_step_counter=train_step_counter,\n",
    "    epsilon_greedy=lambda: epsilon(train_step_counter)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the replay buffer\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=env.batch_size,\n",
    "    max_length=100000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training metrics\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "train_metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.EnvironmentSteps(),\n",
    "    tf_metrics.AverageReturnMetric(),\n",
    "    tf_metrics.AverageEpisodeLengthMetric()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the driver\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "\n",
    "collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env,\n",
    "    policy=agent.collect_policy,\n",
    "    observers=[replay_buffer.add_batch] + train_metrics,\n",
    "    num_steps=4\n",
    ")\n",
    "\n",
    "# Run a random policy to fill the replay buffer\n",
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy\n",
    "\n",
    "initial_collect_policy = RandomTFPolicy(env.time_step_spec(), env.action_spec())\n",
    "init_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env,\n",
    "    policy=initial_collect_policy,\n",
    "    observers=[replay_buffer.add_batch],\n",
    "    num_steps=random_episodes\n",
    ")\n",
    "\n",
    "final_time_step, final_policy_state = init_driver.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/juanpablo/miniconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/juanpablo/miniconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=64,\n",
    "    num_steps=2, # Capaz cambiar esto\n",
    "    num_parallel_calls=3\n",
    ").prefetch(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training loop\n",
    "\n",
    "from tf_agents.utils.common import function\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.eval.metric_utils import log_metrics\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "collect_driver.run = function(collect_driver.run)\n",
    "agent.train = function(agent.train)\n",
    "\n",
    "def train_agent(n_iterations):\n",
    "    time_step = None\n",
    "    policy_state = agent.collect_policy.get_initial_state(env.batch_size)\n",
    "    iterator = iter(dataset)\n",
    "    for iteration in range(n_iterations):\n",
    "        time_step, policy_state = collect_driver.run(time_step, policy_state)\n",
    "        trajectories, buffer_info = next(iterator)\n",
    "        train_loss = agent.train(trajectories)\n",
    "        if iteration % 1000 == 0:\n",
    "            print(\"Iteration: \", iteration)\n",
    "            log_metrics(train_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/juanpablo/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/juanpablo/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1\n",
      "\t\t EnvironmentSteps = 4\n",
      "\t\t AverageReturn = -18.0\n",
      "\t\t AverageEpisodeLength = 4.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 713\n",
      "\t\t EnvironmentSteps = 4004\n",
      "\t\t AverageReturn = -10842.2998046875\n",
      "\t\t AverageEpisodeLength = 28.200000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 865\n",
      "\t\t EnvironmentSteps = 8004\n",
      "\t\t AverageReturn = -11710.5\n",
      "\t\t AverageEpisodeLength = 15.300000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1070\n",
      "\t\t EnvironmentSteps = 12004\n",
      "\t\t AverageReturn = -10784.2998046875\n",
      "\t\t AverageEpisodeLength = 20.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1241\n",
      "\t\t EnvironmentSteps = 16004\n",
      "\t\t AverageReturn = -9240.900390625\n",
      "\t\t AverageEpisodeLength = 29.700000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1409\n",
      "\t\t EnvironmentSteps = 20004\n",
      "\t\t AverageReturn = -6278.89990234375\n",
      "\t\t AverageEpisodeLength = 21.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1592\n",
      "\t\t EnvironmentSteps = 24004\n",
      "\t\t AverageReturn = -1565.199951171875\n",
      "\t\t AverageEpisodeLength = 19.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1770\n",
      "\t\t EnvironmentSteps = 28004\n",
      "\t\t AverageReturn = 6006.0\n",
      "\t\t AverageEpisodeLength = 21.299999237060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 1985\n",
      "\t\t EnvironmentSteps = 32004\n",
      "\t\t AverageReturn = 18726.5\n",
      "\t\t AverageEpisodeLength = 16.299999237060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2259\n",
      "\t\t EnvironmentSteps = 36004\n",
      "\t\t AverageReturn = 35247.69921875\n",
      "\t\t AverageEpisodeLength = 22.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2500\n",
      "\t\t EnvironmentSteps = 40004\n",
      "\t\t AverageReturn = 52717.5\n",
      "\t\t AverageEpisodeLength = 17.799999237060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2728\n",
      "\t\t EnvironmentSteps = 44004\n",
      "\t\t AverageReturn = 70995.1015625\n",
      "\t\t AverageEpisodeLength = 21.200000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  11000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 2961\n",
      "\t\t EnvironmentSteps = 48004\n",
      "\t\t AverageReturn = 89510.6015625\n",
      "\t\t AverageEpisodeLength = 21.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3203\n",
      "\t\t EnvironmentSteps = 52004\n",
      "\t\t AverageReturn = 108915.6015625\n",
      "\t\t AverageEpisodeLength = 20.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  13000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3426\n",
      "\t\t EnvironmentSteps = 56004\n",
      "\t\t AverageReturn = 128021.3984375\n",
      "\t\t AverageEpisodeLength = 19.799999237060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3665\n",
      "\t\t EnvironmentSteps = 60004\n",
      "\t\t AverageReturn = 146974.40625\n",
      "\t\t AverageEpisodeLength = 12.800000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3886\n",
      "\t\t EnvironmentSteps = 64004\n",
      "\t\t AverageReturn = 166073.296875\n",
      "\t\t AverageEpisodeLength = 20.600000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4112\n",
      "\t\t EnvironmentSteps = 68004\n",
      "\t\t AverageReturn = 184662.09375\n",
      "\t\t AverageEpisodeLength = 29.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  17000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4330\n",
      "\t\t EnvironmentSteps = 72004\n",
      "\t\t AverageReturn = 203929.5\n",
      "\t\t AverageEpisodeLength = 19.899999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  18000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4555\n",
      "\t\t EnvironmentSteps = 76004\n",
      "\t\t AverageReturn = 223698.296875\n",
      "\t\t AverageEpisodeLength = 17.899999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  19000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4775\n",
      "\t\t EnvironmentSteps = 80004\n",
      "\t\t AverageReturn = 242319.90625\n",
      "\t\t AverageEpisodeLength = 17.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 4977\n",
      "\t\t EnvironmentSteps = 84004\n",
      "\t\t AverageReturn = 262007.5\n",
      "\t\t AverageEpisodeLength = 18.700000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  21000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 5195\n",
      "\t\t EnvironmentSteps = 88004\n",
      "\t\t AverageReturn = 282395.1875\n",
      "\t\t AverageEpisodeLength = 16.200000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  22000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 5402\n",
      "\t\t EnvironmentSteps = 92004\n",
      "\t\t AverageReturn = 301500.6875\n",
      "\t\t AverageEpisodeLength = 18.399999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  23000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 5606\n",
      "\t\t EnvironmentSteps = 96004\n",
      "\t\t AverageReturn = 321621.3125\n",
      "\t\t AverageEpisodeLength = 16.600000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  24000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 5842\n",
      "\t\t EnvironmentSteps = 100004\n",
      "\t\t AverageReturn = 342219.8125\n",
      "\t\t AverageEpisodeLength = 15.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 6083\n",
      "\t\t EnvironmentSteps = 104004\n",
      "\t\t AverageReturn = 361693.59375\n",
      "\t\t AverageEpisodeLength = 15.800000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  26000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 6296\n",
      "\t\t EnvironmentSteps = 108004\n",
      "\t\t AverageReturn = 382396.09375\n",
      "\t\t AverageEpisodeLength = 23.700000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  27000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 6511\n",
      "\t\t EnvironmentSteps = 112004\n",
      "\t\t AverageReturn = 403843.1875\n",
      "\t\t AverageEpisodeLength = 17.700000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  28000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 6731\n",
      "\t\t EnvironmentSteps = 116004\n",
      "\t\t AverageReturn = 424125.8125\n",
      "\t\t AverageEpisodeLength = 21.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  29000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 6930\n",
      "\t\t EnvironmentSteps = 120004\n",
      "\t\t AverageReturn = 444956.40625\n",
      "\t\t AverageEpisodeLength = 18.799999237060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 7144\n",
      "\t\t EnvironmentSteps = 124004\n",
      "\t\t AverageReturn = 465658.90625\n",
      "\t\t AverageEpisodeLength = 19.899999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  31000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 7344\n",
      "\t\t EnvironmentSteps = 128004\n",
      "\t\t AverageReturn = 486562.59375\n",
      "\t\t AverageEpisodeLength = 17.700000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  32000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 7560\n",
      "\t\t EnvironmentSteps = 132004\n",
      "\t\t AverageReturn = 508596.3125\n",
      "\t\t AverageEpisodeLength = 19.799999237060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  33000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 7760\n",
      "\t\t EnvironmentSteps = 136004\n",
      "\t\t AverageReturn = 529354.6875\n",
      "\t\t AverageEpisodeLength = 17.200000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  34000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 7949\n",
      "\t\t EnvironmentSteps = 140004\n",
      "\t\t AverageReturn = 550497.6875\n",
      "\t\t AverageEpisodeLength = 20.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  35000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 8154\n",
      "\t\t EnvironmentSteps = 144004\n",
      "\t\t AverageReturn = 571727.5\n",
      "\t\t AverageEpisodeLength = 20.399999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  36000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 8352\n",
      "\t\t EnvironmentSteps = 148004\n",
      "\t\t AverageReturn = 592313.875\n",
      "\t\t AverageEpisodeLength = 15.899999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  37000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 8561\n",
      "\t\t EnvironmentSteps = 152004\n",
      "\t\t AverageReturn = 613398.875\n",
      "\t\t AverageEpisodeLength = 14.899999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  38000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 8761\n",
      "\t\t EnvironmentSteps = 156004\n",
      "\t\t AverageReturn = 635592.5\n",
      "\t\t AverageEpisodeLength = 16.200000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  39000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 8940\n",
      "\t\t EnvironmentSteps = 160004\n",
      "\t\t AverageReturn = 656670.5\n",
      "\t\t AverageEpisodeLength = 34.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 9134\n",
      "\t\t EnvironmentSteps = 164004\n",
      "\t\t AverageReturn = 679037.0\n",
      "\t\t AverageEpisodeLength = 19.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  41000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 9318\n",
      "\t\t EnvironmentSteps = 168004\n",
      "\t\t AverageReturn = 700262.3125\n",
      "\t\t AverageEpisodeLength = 23.200000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  42000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 9495\n",
      "\t\t EnvironmentSteps = 172004\n",
      "\t\t AverageReturn = 722991.3125\n",
      "\t\t AverageEpisodeLength = 24.399999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  43000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 9674\n",
      "\t\t EnvironmentSteps = 176004\n",
      "\t\t AverageReturn = 745572.5\n",
      "\t\t AverageEpisodeLength = 19.600000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  44000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 9865\n",
      "\t\t EnvironmentSteps = 180004\n",
      "\t\t AverageReturn = 766755.1875\n",
      "\t\t AverageEpisodeLength = 27.200000762939453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 10037\n",
      "\t\t EnvironmentSteps = 184004\n",
      "\t\t AverageReturn = 788294.8125\n",
      "\t\t AverageEpisodeLength = 24.399999618530273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  46000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 10218\n",
      "\t\t EnvironmentSteps = 188004\n",
      "\t\t AverageReturn = 811772.3125\n",
      "\t\t AverageEpisodeLength = 17.100000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  47000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 10391\n",
      "\t\t EnvironmentSteps = 192004\n",
      "\t\t AverageReturn = 834385.375\n",
      "\t\t AverageEpisodeLength = 27.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  48000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 10561\n",
      "\t\t EnvironmentSteps = 196004\n",
      "\t\t AverageReturn = 856874.5\n",
      "\t\t AverageEpisodeLength = 16.600000381469727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  49000\n"
     ]
    }
   ],
   "source": [
    "train_agent(episodes_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map:\n",
      " [[[0 0 0 3 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 2 1 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 3 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 1 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 3 0]\n",
      "  [0 0 0 1 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 1 0]\n",
      "  [0 3 0 2 0]\n",
      "  [0 0 0 2 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 1 2 0]\n",
      "  [0 3 0 2 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 1 2 2 0]\n",
      "  [0 3 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 2 2 2 3]\n",
      "  [0 1 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 2 2 0 3]\n",
      "  [0 2 1 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 2 0 0 3]\n",
      "  [0 2 2 1 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 3]\n",
      "  [0 2 2 2 1]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 0 0 1]\n",
      "  [0 2 2 2 2]\n",
      "  [0 0 3 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 0 1 2]\n",
      "  [0 0 2 2 2]\n",
      "  [0 0 3 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 1 2 2]\n",
      "  [0 0 0 2 2]\n",
      "  [0 0 3 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 2 2 2]\n",
      "  [0 0 1 0 2]\n",
      "  [0 0 3 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 0 0 0]]]\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 2 2 2]\n",
      "  [0 0 2 0 2]\n",
      "  [0 0 1 0 0]\n",
      "  [0 0 0 0 0]\n",
      "  [0 0 3 0 0]]]\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 2 2 2]\n",
      "  [0 0 2 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [0 0 1 0 0]\n",
      "  [0 0 3 0 0]]]\n",
      "Action:  [3]\n",
      "Map:\n",
      " [[[0 0 2 2 2]\n",
      "  [0 0 2 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [3 0 2 0 0]\n",
      "  [0 0 1 0 0]]]\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 2 2 0]\n",
      "  [0 0 2 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [3 0 2 0 0]\n",
      "  [0 1 2 0 0]]]\n",
      "Action:  [0]\n",
      "Map:\n",
      " [[[0 0 2 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [3 0 2 0 0]\n",
      "  [1 2 2 0 0]]]\n",
      "Action:  [1]\n",
      "Map:\n",
      " [[[0 0 2 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [1 0 2 0 3]\n",
      "  [2 2 2 0 0]]]\n",
      "Action:  [2]\n",
      "Map:\n",
      " [[[0 0 0 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [0 0 2 0 0]\n",
      "  [2 1 2 0 3]\n",
      "  [2 2 2 0 0]]]\n",
      "Action:  [2]\n",
      "Total reward:  121.0\n",
      "Total steps:  21\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the agent\n",
    "\n",
    "time_step = env.reset()\n",
    "rewards = []\n",
    "steps = 0\n",
    "\n",
    "while not time_step.is_last() and steps < 200:\n",
    "    steps += 1\n",
    "    print(\"Map:\\n\", np.argmax(time_step.observation.numpy(), axis=3))\n",
    "    action_step = agent.policy.action(time_step)\n",
    "    print(\"Action: \", action_step.action.numpy())\n",
    "    time_step = env.step(action_step.action)\n",
    "    rewards.append(time_step.reward.numpy()[0])\n",
    "    \n",
    "print(\"Total reward: \", sum(rewards))\n",
    "print(\"Total steps: \", steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  0\n",
      "Episode:  10\n",
      "Episode:  20\n",
      "Episode:  30\n",
      "Episode:  40\n",
      "Episode:  50\n",
      "Episode:  60\n",
      "Episode:  70\n",
      "Episode:  80\n",
      "Episode:  90\n",
      "Episode:  100\n",
      "Episode:  110\n",
      "Episode:  120\n",
      "Episode:  130\n",
      "Episode:  140\n",
      "Episode:  150\n",
      "Episode:  160\n",
      "Episode:  170\n",
      "Episode:  180\n",
      "Episode:  190\n",
      "Episode:  200\n",
      "Episode:  210\n",
      "Episode:  220\n",
      "Episode:  230\n",
      "Episode:  240\n",
      "Episode:  250\n",
      "Episode:  260\n",
      "Episode:  270\n",
      "Episode:  280\n",
      "Episode:  290\n",
      "Episode:  300\n",
      "Episode:  310\n",
      "Episode:  320\n",
      "Episode:  330\n",
      "Episode:  340\n",
      "Episode:  350\n",
      "Episode:  360\n",
      "Episode:  370\n",
      "Episode:  380\n",
      "Episode:  390\n",
      "Episode:  400\n",
      "Episode:  410\n",
      "Episode:  420\n",
      "Episode:  430\n",
      "Episode:  440\n",
      "Episode:  450\n",
      "Episode:  460\n",
      "Episode:  470\n",
      "Episode:  480\n",
      "Episode:  490\n",
      "Average steps per episode:  28.804\n",
      "Average reward per episode:  162.648\n",
      "Total 500 episodes:  0\n"
     ]
    }
   ],
   "source": [
    "# Count the average steps per episode\n",
    "\n",
    "n = 500\n",
    "total_steps = 0\n",
    "total_reward = 0\n",
    "steps = 0\n",
    "total_500 = 0\n",
    "\n",
    "for i in range(n):\n",
    "    if i % 10 == 0:\n",
    "        print(\"Episode: \", i)\n",
    "        \n",
    "    time_step = env.reset()\n",
    "    steps = 0\n",
    "    while not time_step.is_last() and steps < 500:\n",
    "        steps += 1\n",
    "        action_step = agent.policy.action(time_step)\n",
    "        time_step = env.step(action_step.action)\n",
    "        reward = time_step.reward.numpy()[0]\n",
    "        total_reward += reward\n",
    "    \n",
    "    if steps == 500:\n",
    "        total_500 += 1\n",
    "    else:\n",
    "        total_steps += steps\n",
    "        \n",
    "if steps == 500:\n",
    "    print(\"500 episodes reached\")\n",
    "    \n",
    "print(\"Average steps per episode: \", total_steps / (n - total_500))\n",
    "print(\"Average reward per episode: \", total_reward / n)\n",
    "print(\"Total 500 episodes: \", total_500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "this __dict__ descriptor does not support '_DictWrapper' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_agents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicies\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicy_saver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolicySaver\n\u001b[0;32m----> 5\u001b[0m saver \u001b[38;5;241m=\u001b[39m \u001b[43mPolicySaver\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m saver\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/policies/policy_saver.py:333\u001b[0m, in \u001b[0;36mPolicySaver.__init__\u001b[0;34m(self, policy, batch_size, use_nest_path_signatures, seed, train_step, input_fn_and_spec, metadata)\u001b[0m\n\u001b[1;32m    326\u001b[0m get_initial_state_fn\u001b[38;5;241m.\u001b[39mget_concrete_function(\u001b[38;5;241m*\u001b[39mget_initial_state_input_specs)\n\u001b[1;32m    328\u001b[0m train_step_fn \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mfunction(\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: saved_policy\u001b[38;5;241m.\u001b[39mtrain_step\n\u001b[1;32m    330\u001b[0m )\u001b[38;5;241m.\u001b[39mget_concrete_function()\n\u001b[1;32m    331\u001b[0m get_metadata_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\n\u001b[0;32m--> 333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m batched_time_step_spec \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m spec: add_batch_dim(spec, [batch_size]), policy\u001b[38;5;241m.\u001b[39mtime_step_spec\n\u001b[1;32m    337\u001b[0m )\n\u001b[1;32m    338\u001b[0m batched_time_step_spec \u001b[38;5;241m=\u001b[39m cast(ts\u001b[38;5;241m.\u001b[39mTimeStep, batched_time_step_spec)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1227\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1226\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1197\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1201\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:695\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    691\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    692\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    693\u001b[0m )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 695\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    700\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:331\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    328\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_captures\u001b[38;5;241m.\u001b[39mmerge_by_ref_with(graph_capture_container)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# Create a new FunctionType including captures and outputs.\u001b[39;00m\n\u001b[0;32m--> 331\u001b[0m output_type \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraced_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_context\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m traced_func_type \u001b[38;5;241m=\u001b[39m function_type_lib\u001b[38;5;241m.\u001b[39mFunctionType(\n\u001b[1;32m    335\u001b[0m     function_type\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    336\u001b[0m     traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\u001b[38;5;241m.\u001b[39mcapture_types,\n\u001b[1;32m    337\u001b[0m     return_annotation\u001b[38;5;241m=\u001b[39moutput_type,\n\u001b[1;32m    338\u001b[0m )\n\u001b[1;32m    340\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m concrete_function_lib\u001b[38;5;241m.\u001b[39mConcreteFunction\u001b[38;5;241m.\u001b[39mfrom_func_graph(\n\u001b[1;32m    341\u001b[0m     traced_func_graph,\n\u001b[1;32m    342\u001b[0m     traced_func_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:144\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mis_legacy_signature \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, trace\u001b[38;5;241m.\u001b[39mTraceType):\n\u001b[1;32m    143\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[0;32m--> 144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, trace\u001b[38;5;241m.\u001b[39mSupportsTracingProtocol):\n\u001b[1;32m    145\u001b[0m   generated_type \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39m__tf_tracing_type__(context)\n\u001b[1;32m    146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generated_type, trace\u001b[38;5;241m.\u001b[39mTraceType):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/typing_extensions.py:689\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__protocol_attrs__:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 689\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetattr_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/inspect.py:1825\u001b[0m, in \u001b[0;36mgetattr_static\u001b[0;34m(obj, attr, default)\u001b[0m\n\u001b[1;32m   1822\u001b[0m     dict_attr \u001b[38;5;241m=\u001b[39m _shadowed_dict(klass)\n\u001b[1;32m   1823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1824\u001b[0m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types\u001b[38;5;241m.\u001b[39mMemberDescriptorType):\n\u001b[0;32m-> 1825\u001b[0m         instance_result \u001b[38;5;241m=\u001b[39m \u001b[43m_check_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1827\u001b[0m     klass \u001b[38;5;241m=\u001b[39m obj\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/inspect.py:1772\u001b[0m, in \u001b[0;36m_check_instance\u001b[0;34m(obj, attr)\u001b[0m\n\u001b[1;32m   1770\u001b[0m instance_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1772\u001b[0m     instance_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__dict__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m   1774\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: this __dict__ descriptor does not support '_DictWrapper' objects"
     ]
    }
   ],
   "source": [
    "# Save the agent\n",
    "import os\n",
    "from tf_agents.policies.policy_saver import PolicySaver\n",
    "\n",
    "saver = PolicySaver(agent.policy, batch_size=None)\n",
    "saver.save(\"policy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
