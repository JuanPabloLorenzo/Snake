{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tf_agents.networks.q_network import QNetwork\n",
    "import tf_agents.networks.network as network\n",
    "from tf_agents.specs import tensor_spec\n",
    "from snake_game import SnakeGame\n",
    "from scene import Scene\n",
    "from scene_longer_snake import SceneLongerSnake\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input, AveragePooling2D\n",
    "\n",
    "MAP_WIDTH = MAP_HEIGHT = 10\n",
    "BLOCK_SIZE = 15\n",
    "\n",
    "scene = SceneLongerSnake(\n",
    "    init_randomly=True,\n",
    "    map_width=MAP_WIDTH,\n",
    "    map_height=MAP_HEIGHT,\n",
    "    block_size=BLOCK_SIZE,\n",
    "    snake_longer_prob=0.95,\n",
    "    length_mean=16,\n",
    "    length_std=3\n",
    ")\n",
    "episodes_count = 40000\n",
    "random_episodes = 15000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_agents.environments.tf_py_environment import TFPyEnvironment\n",
    "\n",
    "env = SnakeGame(scene)\n",
    "env = TFPyEnvironment(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 10, 10, 4)]       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 32)        544       \n",
      "                                                                 \n",
      " average_pooling2d_2 (Avera  (None, 5, 5, 32)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               102528    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111588 (435.89 KB)\n",
      "Trainable params: 111588 (435.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MyQNetwork(network.Network):\n",
    "    def __init__(self,\n",
    "                 input_tensor_spec,\n",
    "                 action_spec,\n",
    "                 name='MyQNetwork'):\n",
    "        super(MyQNetwork, self).__init__(\n",
    "            input_tensor_spec=input_tensor_spec,\n",
    "            state_spec=(),\n",
    "            name=name)\n",
    "        \n",
    "        self._action_spec = action_spec\n",
    "        matrix_shape = input_tensor_spec.shape\n",
    "        # obstacles_shape = input_tensor_spec[1].shape\n",
    "        # no_body_blocks_shape = input_tensor_spec[2].shape\n",
    "        # relative_food_direction_shape = input_tensor_spec[3].shape\n",
    "        \n",
    "        input0 = Input(shape=matrix_shape)\n",
    "        # input1 = Input(shape=obstacles_shape) # Each value represents if there is a wall or the snake body in the direction, 0 - no wall, 1 - wall\n",
    "        # input2 = Input(shape=no_body_blocks_shape) # Each value represents how many no body blocks are in the direction\n",
    "        # input3 = Input(shape=relative_food_direction_shape)\n",
    "        \n",
    "        conv1 = Conv2D(32, (2, 2), 1, padding=\"same\", activation='relu', kernel_initializer='he_normal')(input0)\n",
    "        maxpool1 = AveragePooling2D((2, 2))(conv1)\n",
    "        flat = Flatten()(maxpool1)\n",
    "        dense1 = Dense(128, activation='relu', kernel_initializer='he_normal')(flat)\n",
    "        dense2 = Dense(64, activation='relu', kernel_initializer='he_normal')(dense1)\n",
    "        \n",
    "        # concat = tf.keras.layers.concatenate([dense3, input1, input2, input3])\n",
    "        # output = Dense(4, activation='linear')(concat)\n",
    "        output = Dense(4, activation='linear')(dense2)\n",
    "        \n",
    "        # self._model = tf.keras.Model(inputs=[input0, input1, input2, input3], outputs=output)\n",
    "        self._model = tf.keras.Model(inputs=[input0], outputs=output)\n",
    "        \n",
    "        self._model.summary()\n",
    "\n",
    "    def call(self, observations, step_type=None, network_state=(), training=False):\n",
    "        # output = self._model([observations[0], observations[1], observations[2], observations[3]])\n",
    "        output = self._model([observations])\n",
    "        return output, network_state\n",
    "\n",
    "q_net = MyQNetwork(\n",
    "    env.observation_spec(),\n",
    "    env.action_spec())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 10, 10, 4)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 32)        544       \n",
      "                                                                 \n",
      " average_pooling2d_3 (Avera  (None, 5, 5, 32)          0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               102528    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111588 (435.89 KB)\n",
      "Trainable params: 111588 (435.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the agent\n",
    "from tf_agents.agents.dqn.dqn_agent import DdqnAgent\n",
    "from tensorflow import keras\n",
    "from keras.optimizers.legacy import Adam\n",
    "from keras.losses import Huber\n",
    "from tf_agents.trajectories import TimeStep\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "optimizer = Adam(learning_rate=0.002)\n",
    "\n",
    "# epsilon = keras.optimizers.schedules.PolynomialDecay(\n",
    "#     initial_learning_rate=0.05,\n",
    "#     decay_steps=episodes_count,\n",
    "#     end_learning_rate=0.002\n",
    "# )\n",
    "\n",
    "agent = DdqnAgent(\n",
    "    time_step_spec=env.time_step_spec(),\n",
    "    action_spec=env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=Huber(reduction=\"none\"),\n",
    "    gamma=tf.constant(0.99, dtype=tf.float32),\n",
    "    train_step_counter=train_step_counter,\n",
    "    epsilon_greedy=lambda: 0#epsilon(train_step_counter)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the replay buffer\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=agent.collect_data_spec,\n",
    "    batch_size=env.batch_size,\n",
    "    max_length=100000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training metrics\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "train_metrics = [\n",
    "    tf_metrics.NumberOfEpisodes(),\n",
    "    tf_metrics.EnvironmentSteps(),\n",
    "    tf_metrics.AverageReturnMetric(),\n",
    "    tf_metrics.AverageEpisodeLengthMetric()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the driver\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "\n",
    "collect_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env,\n",
    "    policy=agent.collect_policy,\n",
    "    observers=[replay_buffer.add_batch] + train_metrics,\n",
    "    num_steps=2\n",
    ")\n",
    "\n",
    "# Run a random policy to fill the replay buffer\n",
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy\n",
    "\n",
    "initial_collect_policy = RandomTFPolicy(env.time_step_spec(), env.action_spec())\n",
    "init_driver = dynamic_step_driver.DynamicStepDriver(\n",
    "    env,\n",
    "    policy=initial_collect_policy,\n",
    "    observers=[replay_buffer.add_batch],\n",
    "    num_steps=random_episodes\n",
    ")\n",
    "\n",
    "final_time_step, final_policy_state = init_driver.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/juanpablo/miniconda3/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
     ]
    }
   ],
   "source": [
    "# Create the dataset\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    sample_batch_size=64,\n",
    "    num_steps=2, # Capaz cambiar esto\n",
    "    num_parallel_calls=5\n",
    ").prefetch(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training loop\n",
    "\n",
    "from tf_agents.utils.common import function\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.eval.metric_utils import log_metrics\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "collect_driver.run = function(collect_driver.run)\n",
    "agent.train = function(agent.train)\n",
    "\n",
    "def train_agent(n_iterations):\n",
    "    time_step = None\n",
    "    policy_state = agent.collect_policy.get_initial_state(env.batch_size)\n",
    "    iterator = iter(dataset)\n",
    "    for iteration in range(n_iterations):\n",
    "        time_step, policy_state = collect_driver.run(time_step, policy_state)\n",
    "        trajectories, buffer_info = next(iterator)\n",
    "        train_loss = agent.train(trajectories)\n",
    "        if iteration % 1000 == 0:\n",
    "            print(\"Iteration: \", iteration)\n",
    "            print(\"Replay buffer len: \" + str(replay_buffer.num_frames().numpy()))\n",
    "            log_metrics(train_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/juanpablo/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 3\n",
      "\t\t EnvironmentSteps = 2\n",
      "\t\t AverageReturn = -80.0\n",
      "\t\t AverageEpisodeLength = 0.3333333432674408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Replay buffer len: 2656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 181\n",
      "\t\t EnvironmentSteps = 2002\n",
      "\t\t AverageReturn = -6944.0\n",
      "\t\t AverageEpisodeLength = 20.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1000\n",
      "Replay buffer len: 4834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 283\n",
      "\t\t EnvironmentSteps = 4002\n",
      "\t\t AverageReturn = -10902.0\n",
      "\t\t AverageEpisodeLength = 23.799999237060547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2000\n",
      "Replay buffer len: 6936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl: \n",
      "\t\t NumberOfEpisodes = 331\n",
      "\t\t EnvironmentSteps = 6002\n",
      "\t\t AverageReturn = -12712.0\n",
      "\t\t AverageEpisodeLength = 44.70000076293945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3000\n",
      "Replay buffer len: 8984\n"
     ]
    }
   ],
   "source": [
    "train_agent(episodes_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate the agent\n",
    "\n",
    "test_scene = Scene(init_randomly=True)\n",
    "test_env = SnakeGame(test_scene)\n",
    "test_env = TFPyEnvironment(test_env)\n",
    "\n",
    "# time_step = test_env.reset()\n",
    "# rewards = []\n",
    "# steps = 0\n",
    "\n",
    "# while not time_step.is_last() and steps < 2000:\n",
    "#     steps += 1\n",
    "#     print(\"Map:\\n\", np.argmax(time_step.observation, axis=3))\n",
    "#     print(\"Direction:\\n\", time_step.observation[1])\n",
    "#     print(\"No body blocks:\\n\", time_step.observation[2])\n",
    "#     action_step = agent.policy.action(time_step)\n",
    "#     print(\"Action: \", action_step.action.numpy())\n",
    "#     time_step = test_env.step(action_step.action)\n",
    "#     rewards.append(time_step.reward.numpy()[0])\n",
    "    \n",
    "# print(\"Total reward: \", sum(rewards))\n",
    "# print(\"Total steps: \", steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:  10\n",
      "Avg reward:  -36.81818181818182\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m time_step\u001b[38;5;241m.\u001b[39mis_last() \u001b[38;5;129;01mand\u001b[39;00m steps \u001b[38;5;241m<\u001b[39m max_steps:\n\u001b[1;32m     18\u001b[0m     steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 19\u001b[0m     action_step \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     time_step \u001b[38;5;241m=\u001b[39m test_env\u001b[38;5;241m.\u001b[39mstep(action_step\u001b[38;5;241m.\u001b[39maction)\n\u001b[1;32m     21\u001b[0m     reward \u001b[38;5;241m=\u001b[39m time_step\u001b[38;5;241m.\u001b[39mreward\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/policies/tf_policy.py:333\u001b[0m, in \u001b[0;36mTFPolicy.action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_automatic_state_reset:\n\u001b[1;32m    332\u001b[0m   policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_reset_state(time_step, policy_state)\n\u001b[0;32m--> 333\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43maction_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclip_action\u001b[39m(action, action_spec):\n\u001b[1;32m    336\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(action_spec, tensor_spec\u001b[38;5;241m.\u001b[39mBoundedTensorSpec):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/utils/common.py:193\u001b[0m, in \u001b[0;36mfunction_in_tf1.<locals>.maybe_wrap.<locals>.with_check_resource_vars\u001b[0;34m(*fn_args, **fn_kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m check_tf1_allowed()\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_eager_been_enabled():\n\u001b[1;32m    191\u001b[0m   \u001b[38;5;66;03m# We're either in eager mode or in tf.function mode (no in-between); so\u001b[39;00m\n\u001b[1;32m    192\u001b[0m   \u001b[38;5;66;03m# autodep-like behavior is already expected of fn.\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resource_variables_enabled():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(MISSING_RESOURCE_VARIABLES_ERROR)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/policies/tf_policy.py:589\u001b[0m, in \u001b[0;36mTFPolicy._action\u001b[0;34m(self, time_step, policy_state, seed)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Implementation of `action`.\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \n\u001b[1;32m    576\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;124;03m    `info`: Optional side information such as action log probabilities.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    588\u001b[0m seed_stream \u001b[38;5;241m=\u001b[39m tfp\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mSeedStream(seed\u001b[38;5;241m=\u001b[39mseed, salt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_agents_tf_policy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 589\u001b[0m distribution_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pytype: disable=wrong-arg-types\u001b[39;00m\n\u001b[1;32m    590\u001b[0m actions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m d: reparameterized_sampling\u001b[38;5;241m.\u001b[39msample(d, seed\u001b[38;5;241m=\u001b[39mseed_stream()),\n\u001b[1;32m    592\u001b[0m     distribution_step\u001b[38;5;241m.\u001b[39maction,\n\u001b[1;32m    593\u001b[0m )\n\u001b[1;32m    594\u001b[0m info \u001b[38;5;241m=\u001b[39m distribution_step\u001b[38;5;241m.\u001b[39minfo\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/policies/greedy_policy.py:82\u001b[0m, in \u001b[0;36mGreedyPolicy._distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour network\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms distribution does not implement mode \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaking it incompatible with a greedy policy.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     78\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m     80\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tfp\u001b[38;5;241m.\u001b[39mdistributions\u001b[38;5;241m.\u001b[39mDeterministic(loc\u001b[38;5;241m=\u001b[39mgreedy_action)\n\u001b[0;32m---> 82\u001b[0m distribution_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped_policy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m policy_step\u001b[38;5;241m.\u001b[39mPolicyStep(\n\u001b[1;32m     86\u001b[0m     tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(dist_fn, distribution_step\u001b[38;5;241m.\u001b[39maction),\n\u001b[1;32m     87\u001b[0m     distribution_step\u001b[38;5;241m.\u001b[39mstate,\n\u001b[1;32m     88\u001b[0m     distribution_step\u001b[38;5;241m.\u001b[39minfo,\n\u001b[1;32m     89\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/policies/tf_policy.py:422\u001b[0m, in \u001b[0;36mTFPolicy.distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_automatic_state_reset:\n\u001b[1;32m    421\u001b[0m   policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_reset_state(time_step, policy_state)\n\u001b[0;32m--> 422\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memit_log_probability:\n\u001b[1;32m    424\u001b[0m   \u001b[38;5;66;03m# This here is set only for compatibility with info_spec in constructor.\u001b[39;00m\n\u001b[1;32m    425\u001b[0m   info \u001b[38;5;241m=\u001b[39m policy_step\u001b[38;5;241m.\u001b[39mset_log_probability(\n\u001b[1;32m    426\u001b[0m       step\u001b[38;5;241m.\u001b[39minfo,\n\u001b[1;32m    427\u001b[0m       tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    430\u001b[0m       ),\n\u001b[1;32m    431\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/policies/q_policy.py:162\u001b[0m, in \u001b[0;36mQPolicy._distribution\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_and_action_constraint_splitter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m   network_observation, mask \u001b[38;5;241m=\u001b[39m observation_and_action_constraint_splitter(\n\u001b[1;32m    159\u001b[0m       network_observation\n\u001b[1;32m    160\u001b[0m   )\n\u001b[0;32m--> 162\u001b[0m q_values, policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_q_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork_observation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m logits \u001b[38;5;241m=\u001b[39m q_values\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observation_and_action_constraint_splitter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;66;03m# Overwrite the logits for invalid actions to logits.dtype.min.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tf_agents/networks/network.py:440\u001b[0m, in \u001b[0;36mNetwork.__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mis_tensor(network_state)\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m network_state \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, ())\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetwork_state\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m call_argspec\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m call_argspec\u001b[38;5;241m.\u001b[39mkeywords\n\u001b[1;32m    437\u001b[0m ):\n\u001b[1;32m    438\u001b[0m   normalized_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetwork_state\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 440\u001b[0m outputs, new_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnormalized_kwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pytype: disable=attribute-error  # typed-keras\u001b[39;00m\n\u001b[1;32m    442\u001b[0m nest_utils\u001b[38;5;241m.\u001b[39massert_matching_dtypes_and_inner_shapes(\n\u001b[1;32m    443\u001b[0m     new_state,\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate_spec,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m     specs_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`state_spec`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    449\u001b[0m )\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs, new_state\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1149\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 39\u001b[0m, in \u001b[0;36mMyQNetwork.call\u001b[0;34m(self, observations, step_type, network_state, training)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, observations, step_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, network_state\u001b[38;5;241m=\u001b[39m(), training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# output = self._model([observations[0], observations[1], observations[2], observations[3]])\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output, network_state\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:590\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    588\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1148\u001b[0m ):\n\u001b[0;32m-> 1149\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/functional.py:515\u001b[0m, in \u001b[0;36mFunctional.call\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    498\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m    In this case `call` just reapplies\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/functional.py:654\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    652\u001b[0m tensor_usage_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_usage_count\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs, inputs):\n\u001b[0;32m--> 654\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conform_to_reference_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m     x_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(x))\n\u001b[1;32m    656\u001b[0m     tensor_dict[x_id] \u001b[38;5;241m=\u001b[39m [y] \u001b[38;5;241m*\u001b[39m tensor_usage_count[x_id]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/functional.py:751\u001b[0m, in \u001b[0;36mFunctional._conform_to_reference_input\u001b[0;34m(self, tensor, ref_input)\u001b[0m\n\u001b[1;32m    748\u001b[0m         tensor\u001b[38;5;241m.\u001b[39m_keras_history \u001b[38;5;241m=\u001b[39m keras_history\n\u001b[1;32m    750\u001b[0m     \u001b[38;5;66;03m# Dtype casting.\u001b[39;00m\n\u001b[0;32m--> 751\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(tensor, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mref_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m)\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tf_utils\u001b[38;5;241m.\u001b[39mis_extension_type(tensor):\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;66;03m# Dtype casting (If the extension type has a non-variant dtype and\u001b[39;00m\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;66;03m# supports being cast).  Only cast if necessary (since some\u001b[39;00m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# extension types may not implement tf.cast).\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     tensor_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/keras_tensor.py:366\u001b[0m, in \u001b[0;36mKerasTensor.dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(type_spec, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKerasTensor wraps TypeSpec \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(type_spec)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich does not have a dtype.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m     )\n\u001b[0;32m--> 366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mtype_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m, tf\u001b[38;5;241m.\u001b[39mDType):\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    368\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKerasTensor requires that wrapped TypeSpec\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms dtype is a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDType; got TypeSpec \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(type_spec)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, whose \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype field has unexpected type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(type_spec\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m     )\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m type_spec\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py:875\u001b[0m, in \u001b[0;36mDenseSpec.dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the `TensorShape` that represents the shape of the tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdtype\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the `dtype` of elements in the tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Count the average steps per episode\n",
    "\n",
    "n = 100\n",
    "total_steps = 0\n",
    "total_reward = 0\n",
    "steps = 0\n",
    "max_steps = 2000\n",
    "total_max_steps = 0\n",
    "\n",
    "for i in range(n):\n",
    "    if i % 10 == 0 and i != 0:\n",
    "        print(\"Episode: \", i)\n",
    "        \n",
    "    time_step = test_env.reset()\n",
    "    steps = 0\n",
    "    episode_reward = 0\n",
    "    while not time_step.is_last() and steps < max_steps:\n",
    "        steps += 1\n",
    "        action_step = agent.policy.action(time_step)\n",
    "        time_step = test_env.step(action_step.action)\n",
    "        reward = time_step.reward.numpy()[0]\n",
    "        total_reward += reward\n",
    "        episode_reward += reward\n",
    "        \n",
    "    if steps == max_steps:\n",
    "        total_max_steps += 1\n",
    "    else:\n",
    "        total_steps += steps\n",
    "        \n",
    "    if i % 10 == 0 and i != 0:\n",
    "        print(\"Avg reward: \", total_reward / (i + 1))\n",
    "        \n",
    "print(\"Average steps per episode: \", total_steps / (n - total_max_steps))\n",
    "print(\"Average reward per episode: \", total_reward / n)\n",
    "print(\"Total max steps episodes: \", total_max_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bw/_7s8wxw93cngpt5f7bg5s3hm0000gn/T/ipykernel_35888/4294134740.py:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(q_net._model, \"q_network_10x10.h5\")\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Save the q network weights\n",
    "tf.keras.models.save_model(q_net._model, \"q_network_10x10.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_weights = q_net._model.weights[-2].numpy()\n",
    "\n",
    "# Plot the weights. In the y axis are the 4 actions, in the x axis are the 28 neurons of the last dense layer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(layer_weights, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
